# -*- coding: utf-8 -*-
"""classification model 2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Gr4a-6hoM6glOAhFDDeW5i3IqK3VKgYw

#prerun
"""

!pip install ta
!pip install backtesting

import pandas as pd
import ta
from sklearn.model_selection import train_test_split
import xgboost as xgb
import pickle

#for backtesting
from backtesting import Backtest, Strategy
from backtesting.lib import crossover
import numpy as np

#for plotting
import pandas as pd
import matplotlib.pyplot as plt
import plotly.graph_objects as go

"""#main functions"""

class Dataset:
    def __init__(self, file, threshold , window):
        self.file = file
        self.threshold = threshold
        self.window = window

    def set(self, file, period_buy, period_sell, buy_threshold, sell_threshold):
        self.file = file
        self.period_buy = period_buy
        self.period_sell = period_sell
        self.buy_threshold = buy_threshold
        self.sell_threshold = sell_threshold

    def signal_setting(self):
        try:
            # Load from csv if file is a string
            if isinstance(self.file, str):
                df = pd.read_csv(self.file)
            # If file is already a DataFrame
            elif isinstance(self.file, pd.DataFrame):
                df = self.file
            else:
                raise TypeError("File should be a string or a DataFrame")
        except Exception as e:
            print("Error loading dataset:", e)
            return None

        # Calculate EMA 50 and EMA 200
        df['ema_50'] = ta.trend.ema_indicator(close=df['Close'], window=50)
        df['ema_200'] = ta.trend.ema_indicator(close=df['Close'], window=200)

        # Calculate MACD
        df['macd'] = ta.trend.macd_diff(close=df['Close'])

        # Calculate RSI
        df['rsi'] = ta.momentum.rsi(close=df['Close'], window=14)

        # Calculate Stochastic Oscillator
        df['stoch_oscillator'] = ta.momentum.stoch(close=df['Close'] , high=df["High"] , low=df["Low"])

        # Calculate Average True Range (ATR)
        df['atr'] = ta.volatility.average_true_range(high=df['High'], low=df['Low'], close=df['Close'])

        # Calculate On-Balance Volume (OBV)
        df['obv'] = ta.volume.on_balance_volume(close=df['Close'], volume=df['Volume'])

        # Calculate Ichimoku Cloud
        df['ichimoku_a'] = ta.trend.ichimoku_a(high=df['High'], low=df['Low'])

        # Drop rows with NaN values
        df.dropna(inplace=True)

        # Convert 'close' column to float
        df['Close'] = pd.to_numeric(df['Close'], errors='coerce')



        #calculate
        window_size = self.window
        min = self.threshold
        step_size = window_size



        # Divide the DataFrame into equal parts
        num_windows = len(df) // window_size
        windows = [df.iloc[i * window_size:(i + 1) * window_size] for i in range(num_windows)]

        # Iterate over each window
        for window in windows:
            # Calculate highest and lowest points within the window
            highest_point = window['Close'].max()
            lowest_point = window['Close'].min()

            # Calculate the difference between the highest and lowest points
            diff = (highest_point - lowest_point) / lowest_point

            # If the difference is greater than 0.1, mark the points as valid
            if diff > min:
                highest_index = window[window['Close'] == highest_point].index[0]
                lowest_index = window[window['Close'] == lowest_point].index[0]

                # Set 'sell' to 1 for the highest point and 'buy' to 1 for the lowest point
                df.at[highest_index, 'sell'] = 1
                df.at[lowest_index, 'buy'] = 1

        # Fill NaN values in 'buy' and 'sell' columns with 0
        df['buy'].fillna(0, inplace=True)
        df['sell'].fillna(0, inplace=True)




        # Assuming df is your DataFrame
        selected_cols = ['Date','Open','High','Low','Close','Volume','ema_50', 'ema_200', 'macd', 'rsi', 'stoch_oscillator', 'atr', 'obv', 'ichimoku_a','buy','sell']

        # Create a copy of the DataFrame with only selected columns
        df = df.loc[:, selected_cols].copy()




        #update
        self.df = df
        return df

    def monitor(self):
        #df
        df = self.df

        #counts
        total = len(df)
        hold = ((df['buy'] == 0) & (df['sell'] == 0)).sum()
        buy = ((df['buy'] == 1)).sum()
        sell = ((df['sell'] == 1)).sum()

        #percentages
        buy_p = buy/total * 100
        sell_p = sell/total * 100
        hold_p = hold/total * 100

        print(f"""
              hold count : {hold}
              buy count : {buy}
              sell count : {sell}

              hold percentage : {hold_p} %
              buy percentage : {buy_p} %
              sell percentage : {sell_p} %
        """)

        return buy_p , sell_p , hold_p


    def train(self):

      #df
      df = self.df


      #train buy

      # Separate rows where buy = 0 and buy = 1 into different DataFrames
      df_buy_0 = df[df['buy'] == 0]
      df_buy_1 = df[df['buy'] == 1]

      # Determine the minimum count of buy = 0 and buy = 1
      min_count = min(len(df_buy_0), len(df_buy_1))

      # Sample randomly from each DataFrame to get the required number of rows
      df_buy_0_sampled = df_buy_0.sample(n=min_count, random_state=42)
      df_buy_1_sampled = df_buy_1.sample(n=min_count, random_state=42)

      # Concatenate the sampled DataFrames to get the final balanced dataset
      df_balanced = pd.concat([df_buy_0_sampled, df_buy_1_sampled])

      # Shuffle the rows
      df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)

      # Prepare the data for training
      X = df_balanced.drop(columns=['Date', 'buy', 'sell' , 'Close' ,'Open','High','Low','Volume'])  # Features
      y = df_balanced['buy']  # Target variable



      # Split the data into training and testing sets
      X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

      # Train the XGBoost classifier
      model_buy = xgb.XGBClassifier()
      model_buy.fit(X_train, y_train)


      #self
      self.model_buy = model_buy

      # Save the trained model to a file
      with open('model_buy.pickle', 'wb') as f:
          pickle.dump(model_buy, f)

      # Load the saved model from file
      with open('model_buy.pickle', 'rb') as f:
          loaded_model_buy = pickle.load(f)

      # Evaluate the model's performance
      train_accuracy = loaded_model_buy.score(X_train, y_train)
      test_accuracy = loaded_model_buy.score(X_test, y_test)

      print("Training Accuracy(buy):", train_accuracy)
      print("Testing Accuracy:(buy)", test_accuracy)


      #df
      df = self.df

      # Separate rows where sell = 0 and sell = 1 into different DataFrames
      df_sell_0 = df[df['sell'] == 0]
      df_sell_1 = df[df['sell'] == 1]

      # Determine the minimum count of sell = 0 and sell = 1
      min_count = min(len(df_sell_0), len(df_sell_1))

      # Sample randomly from each DataFrame to get the required number of rows
      df_sell_0_sampled = df_sell_0.sample(n=min_count, random_state=42)
      df_sell_1_sampled = df_sell_1.sample(n=min_count, random_state=42)

      # Concatenate the sampled DataFrames to get the final balanced dataset
      df_balanced_sell = pd.concat([df_sell_0_sampled, df_sell_1_sampled])

      # Shuffle the rows
      df_balanced_sell = df_balanced_sell.sample(frac=1, random_state=42).reset_index(drop=True)

      # Prepare the data for training
      X_sell = df_balanced_sell.drop(columns=['Date', 'buy', 'sell' , 'Close' ,'Open','High','Low','Volume'])  # Features
      y_sell = df_balanced_sell['sell']  # Target variable



      # Split the data into training and testing sets
      X_train_sell, X_test_sell, y_train_sell, y_test_sell = train_test_split(X_sell, y_sell, test_size=0.2, random_state=42)

      # Train the XGBoost classifier
      model_sell = xgb.XGBClassifier()
      model_sell.fit(X_train_sell, y_train_sell)

      #self
      self.model_sell = model_sell

      # Save the trained model to a file
      with open('model_sell.pickle', 'wb') as f:
          pickle.dump(model_sell, f)

      # Load the saved model from file
      with open('model_sell.pickle', 'rb') as f:
          loaded_model_sell = pickle.load(f)

      # Evaluate the model's performance
      train_accuracy_sell = loaded_model_sell.score(X_train_sell, y_train_sell)
      test_accuracy_sell = loaded_model_sell.score(X_test_sell, y_test_sell)

      print("Training Accuracy (Sell):", train_accuracy_sell)
      print("Testing Accuracy (Sell):", test_accuracy_sell)



    def load_models(self,model_buy,model_sell):
        # Load the saved model from file
        with open(model_buy, 'rb') as f:
            loaded_model_buy = pickle.load(f)

        with open(model_sell, 'rb') as f:
            loaded_model_sell = pickle.load(f)


        self.model_buy = loaded_model_buy
        self.model_sell = loaded_model_sell



    def get_signal(self,df):
        # Use the loaded model to make prediction for the single record
        prediction_sell = self.model_sell.predict(df)
        prediction_sell = prediction_sell[0]

        prediction_buy = self.model_buy.predict(df)
        prediction_buy = prediction_buy[0]

        if prediction_buy == 1 and prediction_sell == 0 :
          return "buy"
        elif prediction_buy == 0 and prediction_sell == 1 :
          return "sell"
        else :
          return "hold"


    def save_instance(instance, file_name):
        with open(file_name, 'wb') as f:
            pickle.dump(instance, f)

    def load_instance(file_name):
        with open(file_name, 'rb') as f:
            instance = pickle.load(f)
        return instance


    def plot (self):
        df = self.df
        df['Date'] = pd.to_datetime(df['Date'])

        # Create traces for close prices, buy points, and sell points
        trace_close = go.Scatter(x=df['Date'], y=df['Close'], mode='lines', name='Close')
        trace_buy = go.Scatter(x=df[df['buy'] == 1]['Date'], y=df[df['buy'] == 1]['Close'], mode='markers', marker=dict(color='green'), name='Buy')
        trace_sell = go.Scatter(x=df[df['sell'] == 1]['Date'], y=df[df['sell'] == 1]['Close'], mode='markers', marker=dict(color='red'), name='Sell')

        # Create figure object
        fig = go.Figure()

        # Add traces to the figure
        fig.add_trace(trace_close)
        fig.add_trace(trace_buy)
        fig.add_trace(trace_sell)

        # Update layout
        fig.update_layout(
            title='Close Price with Buy and Sell Points',
            xaxis=dict(title='Date'),
            yaxis=dict(title='Close Price'),
            showlegend=True
        )

        # Show plot
        fig.show()

"""#documentation


"""

#data
file1 = "Binance_SOLUSDT_d.csv"
file2 = "SOLUSDT1.csv"
#-----------------------------

#to choose the minimum profit between valid buy and sell points
threshold = 0.6

#to choose the window in which the trade happened
window = 20

#to create the object instance
instance = Dataset(file1, threshold, window )

#to create the valid buy and sell points
df = instance.signal_setting()

#to save the data frame with features and points
df.to_csv("df.csv")

#to plot the choosen buy and sell points
instance.plot()

#to print the states (number of buy / sell points)
instance.monitor()

#to train the buy and sell models on the created dataset
instance.train()

#demo of using the models to get signals

#features
single_record = {
    'ema_50': 19.502773,
    'ema_200': 19.545588,
    'macd': -0.007156,
    'rsi': 53.699608,
    'stoch_oscillator': 75.2345,
    'atr': 1.5,
    'obv': 10000,
    'ichimoku_a': 20.5,

                }

# Convert the single record into a DataFrame
df_single = pd.DataFrame([single_record])

#to get signals
signal = instance.get_signal(df_single)
print(signal)

"""#backtest"""

#data
data_test = file1
df = pd.read_csv(data_test)
#-------------------------

#adding feature to the dataset records

# Calculate EMA 50 and EMA 200
df['ema_50'] = ta.trend.ema_indicator(close=df['Close'], window=50)
df['ema_200'] = ta.trend.ema_indicator(close=df['Close'], window=200)

# Calculate MACD
df['macd'] = ta.trend.macd_diff(close=df['Close'])

# Calculate RSI
df['rsi'] = ta.momentum.rsi(close=df['Close'], window=14)

# Calculate Stochastic Oscillator
df['stoch_oscillator'] = ta.momentum.stoch(close=df['Close'], high=df["High"] , low=df["Low"])

# Calculate Average True Range (ATR)
df['atr'] = ta.volatility.average_true_range(high=df['High'], low=df['Low'], close=df['Close'])

# Calculate On-Balance Volume (OBV)
df['obv'] = ta.volume.on_balance_volume(close=df['Close'], volume=df['Volume'])

# Calculate Ichimoku Cloud
df['ichimoku_a'] = ta.trend.ichimoku_a(high=df['High'], low=df['Low'])

# Drop rows with NaN values
df.dropna(inplace=True)





#backtest class
class str(Strategy):
    def init(self):
        pass

    def next(self):

        # Get current record features
        current_df = {
          'ema_50': self.data.ema_50[-1],
          'ema_200': self.data.ema_200[-1],
          'macd': self.data.macd[-1],
          'rsi': self.data.rsi[-1],
          'stoch_oscillator': self.data.stoch_oscillator[-1],
          'atr': self.data.atr[-1],
          'obv': self.data.obv[-1],
          'ichimoku_a': self.data.ichimoku_a[-1]

                      }

        # Convert current_df into a DataFrame
        df_single = pd.DataFrame([current_df])

        # Use df_single to get signals
        signal = instance.get_signal(df_single)

        # Execute trades based on the signal
        if "buy" in signal :
            self.buy()

        elif "sell" in signal :
            self.position.close()

#run backtest
bt = Backtest(df, str,
              cash=1000, commission=0.0,
              exclusive_orders=False)

output = bt.run()

#print backtest results
print(output)

#plot buy and sell points
bt.plot()